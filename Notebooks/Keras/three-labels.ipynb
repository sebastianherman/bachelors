{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import contractions\n",
    "\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_data_5k = pd.read_csv(\"/home/sebastian/Documents/bachelor-final/Dataset/PROCESSED_RESTAURANT_REVIEWS_5k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "      <th>rating</th>\n",
       "      <th>restaurantID</th>\n",
       "      <th>reviewCleanWithStopwords</th>\n",
       "      <th>reviewCleanNoStopwords</th>\n",
       "      <th>reviewCleanPorterStemmer</th>\n",
       "      <th>reviewCleanSnowballStemmer</th>\n",
       "      <th>reviewCleanLemmatized</th>\n",
       "      <th>reviewCleanLancaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"'Check, Please.\" The bartender was unable to ...</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>VZHyAmdFDreQqL0BT-zdoA</td>\n",
       "      <td>check please the bartender was unable to recom...</td>\n",
       "      <td>check please bartender unable recommend beer t...</td>\n",
       "      <td>check pleas bartend unabl recommend beer tap t...</td>\n",
       "      <td>check pleas bartend unabl recommend beer tap t...</td>\n",
       "      <td>check please bartender unable recommend beer t...</td>\n",
       "      <td>check pleas bartend un recommend beer tap tri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"2 stars for disappointing food, one star for ...</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>tFcmrGLZNEymSnijoTPmqw</td>\n",
       "      <td>stars for disappointing food one star for grea...</td>\n",
       "      <td>stars disappointing food one star great servic...</td>\n",
       "      <td>star disappoint food one star great servic rea...</td>\n",
       "      <td>star disappoint food one star great servic rea...</td>\n",
       "      <td>star disappoint food one star great service re...</td>\n",
       "      <td>star disappoint food on star gre serv read iai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"A Divine Dialogue\" God: \"Britton. Times up. T...</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>INvIaBFnAvGxzTXFWHzGvA</td>\n",
       "      <td>divine dialogue god britton times up the world...</td>\n",
       "      <td>divine dialogue god britton times world going ...</td>\n",
       "      <td>divin dialogu god britton time world go end to...</td>\n",
       "      <td>divin dialogu god britton time world go end to...</td>\n",
       "      <td>divine dialogue god britton time world go end ...</td>\n",
       "      <td>divin dialog god britton tim world going end t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"A Place To Go When You Have Time\" It was a mi...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>FySId5SjNhkrtPA5qktdxg</td>\n",
       "      <td>place to go when you have time it was misty br...</td>\n",
       "      <td>place go time misty breezy summer night friend...</td>\n",
       "      <td>place go time misti breezi summer night friend...</td>\n",
       "      <td>place go time misti breezi summer night friend...</td>\n",
       "      <td>place go time misty breezy summer night friend...</td>\n",
       "      <td>plac go tim misty breezy sum night friend jere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"A Thaiphoon of Flavor\" My First: I never enli...</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>RgeMUiZncTs-VSHQLm0wNg</td>\n",
       "      <td>thaiphoon of flavor my first never enlisted in...</td>\n",
       "      <td>thaiphoon flavor first never enlisted air forc...</td>\n",
       "      <td>thaiphoon flavor first never enlist air forc a...</td>\n",
       "      <td>thaiphoon flavor first never enlist air forc a...</td>\n",
       "      <td>thaiphoon flavor first never enlist air force ...</td>\n",
       "      <td>thaiphoon flav first nev enl air forc allow jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      reviewContent  usefulCount  \\\n",
       "0           0  \"'Check, Please.\" The bartender was unable to ...           18   \n",
       "1           1  \"2 stars for disappointing food, one star for ...           14   \n",
       "2           2  \"A Divine Dialogue\" God: \"Britton. Times up. T...           14   \n",
       "3           3  \"A Place To Go When You Have Time\" It was a mi...           13   \n",
       "4           4  \"A Thaiphoon of Flavor\" My First: I never enli...           27   \n",
       "\n",
       "   coolCount  funnyCount  rating            restaurantID  \\\n",
       "0         11          25       1  VZHyAmdFDreQqL0BT-zdoA   \n",
       "1         10           7       3  tFcmrGLZNEymSnijoTPmqw   \n",
       "2         16          23       5  INvIaBFnAvGxzTXFWHzGvA   \n",
       "3         10          10       5  FySId5SjNhkrtPA5qktdxg   \n",
       "4         22          28       5  RgeMUiZncTs-VSHQLm0wNg   \n",
       "\n",
       "                            reviewCleanWithStopwords  \\\n",
       "0  check please the bartender was unable to recom...   \n",
       "1  stars for disappointing food one star for grea...   \n",
       "2  divine dialogue god britton times up the world...   \n",
       "3  place to go when you have time it was misty br...   \n",
       "4  thaiphoon of flavor my first never enlisted in...   \n",
       "\n",
       "                              reviewCleanNoStopwords  \\\n",
       "0  check please bartender unable recommend beer t...   \n",
       "1  stars disappointing food one star great servic...   \n",
       "2  divine dialogue god britton times world going ...   \n",
       "3  place go time misty breezy summer night friend...   \n",
       "4  thaiphoon flavor first never enlisted air forc...   \n",
       "\n",
       "                            reviewCleanPorterStemmer  \\\n",
       "0  check pleas bartend unabl recommend beer tap t...   \n",
       "1  star disappoint food one star great servic rea...   \n",
       "2  divin dialogu god britton time world go end to...   \n",
       "3  place go time misti breezi summer night friend...   \n",
       "4  thaiphoon flavor first never enlist air forc a...   \n",
       "\n",
       "                          reviewCleanSnowballStemmer  \\\n",
       "0  check pleas bartend unabl recommend beer tap t...   \n",
       "1  star disappoint food one star great servic rea...   \n",
       "2  divin dialogu god britton time world go end to...   \n",
       "3  place go time misti breezi summer night friend...   \n",
       "4  thaiphoon flavor first never enlist air forc a...   \n",
       "\n",
       "                               reviewCleanLemmatized  \\\n",
       "0  check please bartender unable recommend beer t...   \n",
       "1  star disappoint food one star great service re...   \n",
       "2  divine dialogue god britton time world go end ...   \n",
       "3  place go time misty breezy summer night friend...   \n",
       "4  thaiphoon flavor first never enlist air force ...   \n",
       "\n",
       "                                reviewCleanLancaster  \n",
       "0  check pleas bartend un recommend beer tap tri ...  \n",
       "1  star disappoint food on star gre serv read iai...  \n",
       "2  divin dialog god britton tim world going end t...  \n",
       "3  plac go tim misty breezy sum night friend jere...  \n",
       "4  thaiphoon flav first nev enl air forc allow jo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data_5k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1250\n",
       "5    1179\n",
       "1    1159\n",
       "3    1130\n",
       "4    1051\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data_5k.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data_5k.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    accuracy = history.history['acc']\n",
    "    val_accuracy = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(1,len(accuracy) + 1)\n",
    "    \n",
    "    # Plot accuracy  \n",
    "    plt.figure(1)\n",
    "    plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'g', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove data from table with rating = 2 or 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of indexes for which column rating has value 2\n",
    "indexNamesRating2 = yelp_data_5k[ yelp_data_5k['rating'] == 2 ].index\n",
    " \n",
    "# Delete these row indexes from dataFrame\n",
    "yelp_data_5k.drop(indexNamesRating2, inplace=True)\n",
    "\n",
    "# Get names of indexes for which column rating has value 4\n",
    "indexNamesRating4 = yelp_data_5k[ yelp_data_5k['rating'] == 4 ].index\n",
    " \n",
    "# Delete these row indexes from dataFrame\n",
    "yelp_data_5k.drop(indexNamesRating4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1179\n",
       "1    1159\n",
       "3    1130\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data_5k.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allocating each text with its specific cleaning method to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cleanWithStopwords = yelp_data_5k[\"reviewCleanWithStopwords\"]\n",
    "x_cleanNoStopwords = yelp_data_5k[\"reviewCleanNoStopwords\"]\n",
    "x_porterStemmer = yelp_data_5k[\"reviewCleanPorterStemmer\"]\n",
    "x_snowballStemmer = yelp_data_5k[\"reviewCleanSnowballStemmer\"]\n",
    "x_lemmatized = yelp_data_5k[\"reviewCleanLemmatized\"]\n",
    "x_lancaster = yelp_data_5k[\"reviewCleanLancaster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_cleanWithStopwords)\n",
    "x_cleanWithStopwords = tf.transform(x_cleanWithStopwords)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_cleanNoStopwords)\n",
    "x_cleanNoStopwords = tf.transform(x_cleanNoStopwords)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_porterStemmer)\n",
    "x_porterStemmer = tf.transform(x_porterStemmer)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_snowballStemmer)\n",
    "x_snowballStemmer = tf.transform(x_snowballStemmer)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_lemmatized)\n",
    "x_lemmatized = tf.transform(x_lemmatized)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_lancaster)\n",
    "x_lancaster = tf.transform(x_lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_cleanWithStopwords = SelectKBest(f_classif, k=min(19132, x_cleanWithStopwords.shape[1]))\n",
    "selector_cleanNoStopwords = SelectKBest(f_classif, k=min(19132, x_cleanNoStopwords.shape[1]))\n",
    "selector_porterStemmer = SelectKBest(f_classif, k=min(19132, x_porterStemmer.shape[1]))\n",
    "selector_snowballStemmer = SelectKBest(f_classif, k=min(19132, x_snowballStemmer.shape[1]))\n",
    "selector_lemmatized = SelectKBest(f_classif, k=min(19132, x_lemmatized.shape[1]))\n",
    "selector_lancaster = SelectKBest(f_classif, k=min(19132, x_lancaster.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = yelp_data_5k.rating.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=19132, score_func=<function f_classif at 0x7f62f0f87b70>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_cleanWithStopwords.fit(x_cleanWithStopwords, y)\n",
    "selector_cleanNoStopwords.fit(x_cleanNoStopwords, y)\n",
    "selector_porterStemmer.fit(x_porterStemmer, y)\n",
    "selector_snowballStemmer.fit(x_snowballStemmer, y)\n",
    "selector_lemmatized.fit(x_lemmatized, y)\n",
    "selector_lancaster.fit(x_lancaster, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cleanWithStopwords = selector_cleanWithStopwords.transform(x_cleanWithStopwords).astype('float32')\n",
    "x_cleanNoStopwords = selector_cleanNoStopwords.transform(x_cleanNoStopwords).astype('float32')\n",
    "x_porterStemmer = selector_porterStemmer.transform(x_porterStemmer).astype('float32')\n",
    "x_snowballStemmer = selector_snowballStemmer.transform(x_snowballStemmer).astype('float32')\n",
    "x_lemmatized = selector_lemmatized.transform(x_lemmatized).astype('float32')\n",
    "x_lancaster = selector_lancaster.transform(x_lancaster).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleanWithStopwords = x_cleanWithStopwords.toarray()\n",
    "X_cleanNoStopwords = x_cleanNoStopwords.toarray()\n",
    "X_porterStemmer = x_porterStemmer.toarray()\n",
    "X_snowballStemmer = x_snowballStemmer.toarray()\n",
    "X_lemmatized = x_lemmatized.toarray()\n",
    "X_lancaster = x_lancaster.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = yelp_data_5k['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleanWithStopwords, X_test_cleanWithStopwords, y_train, y_test = train_test_split(X_cleanWithStopwords, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_cleanNoStopwords, X_test_cleanNoStopwords, y_train, y_test = train_test_split(X_cleanNoStopwords, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_porterStemmer, X_test_porterStemmer, y_train, y_test = train_test_split(X_porterStemmer, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_snowballStemmer, X_test_snowballStemmer, y_train, y_test = train_test_split(X_snowballStemmer, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_lemmatized, X_test_lemmatized, y_train, y_test = train_test_split(X_lemmatized, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_lancaster, X_test_lancaster, y_train, y_test = train_test_split(X_lancaster, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train_cleanNoStopwords.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19132,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 19:06:29.592908 140064191469376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0703 19:06:29.602348 140064191469376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0703 19:06:29.603866 140064191469376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0703 19:06:29.608847 140064191469376 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0703 19:06:29.619791 140064191469376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_1 (Dropout)          (None, 19132)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1224512   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,224,707\n",
      "Trainable params: 1,224,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(rate=0.2, input_shape = input_shape))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 19:06:33.457606 140064191469376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0703 19:06:33.461236 140064191469376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 19:06:35.763130 140064191469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2774 samples, validate on 694 samples\n",
      "Epoch 1/100\n",
      "2774/2774 [==============================] - 1s 448us/step - loss: nan - acc: 0.0011 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2774/2774 [==============================] - 1s 185us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Train on 2774 samples, validate on 694 samples\n",
      "Epoch 1/100\n",
      "2774/2774 [==============================] - 0s 72us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2774/2774 [==============================] - 0s 70us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Train on 2774 samples, validate on 694 samples\n",
      "Epoch 1/100\n",
      "2774/2774 [==============================] - 0s 71us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2774/2774 [==============================] - 0s 73us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Train on 2774 samples, validate on 694 samples\n",
      "Epoch 1/100\n",
      "2774/2774 [==============================] - 0s 73us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2774/2774 [==============================] - 0s 69us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Train on 2774 samples, validate on 694 samples\n",
      "Epoch 1/100\n",
      "2774/2774 [==============================] - 0s 69us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2774/2774 [==============================] - 0s 70us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Train on 2774 samples, validate on 694 samples\n",
      "Epoch 1/100\n",
      "2774/2774 [==============================] - 0s 69us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2774/2774 [==============================] - 0s 69us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history_cleanWithStopwords = model.fit(X_train_cleanWithStopwords, y_train, epochs=100, validation_data=(X_test_cleanWithStopwords, y_test), verbose=1, batch_size=16, callbacks=callbacks)\n",
    "\n",
    "history_cleanNoStopwords = model.fit(X_train_cleanNoStopwords, y_train, epochs=100, validation_data=(X_test_cleanNoStopwords, y_test), verbose=1, batch_size=64, callbacks=callbacks)\n",
    "\n",
    "history_porterStemmer = model.fit(X_train_porterStemmer, y_train, epochs=100, validation_data=(X_test_porterStemmer, y_test), verbose=1, batch_size=64, callbacks=callbacks)\n",
    "\n",
    "history_snowballStemmer = model.fit(X_train_snowballStemmer, y_train, epochs=100, validation_data=(X_test_snowballStemmer, y_test), verbose=1, batch_size=64, callbacks=callbacks)\n",
    "\n",
    "history_lemmatized = model.fit(X_train_lemmatized, y_train, epochs=100, validation_data=(X_test_lemmatized, y_test), verbose=1, batch_size=64, callbacks=callbacks)\n",
    "\n",
    "history_lancaster = model.fit(X_train_lancaster, y_train, epochs=100, validation_data=(X_test_lancaster, y_test), verbose=1, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_cleanWithStopwords, y_test, verbose=1)\n",
    "print('WITH STOPWORDS')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_cleanNoStopwords, y_test, verbose=1)\n",
    "print('NO STOPWORDS')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_porterStemmer, y_test, verbose=1)\n",
    "print('PORTERSTEMMER')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_snowballStemmer, y_test, verbose=1)\n",
    "print('SNOWBALLSTEMMER')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_lemmatized, y_test, verbose=1)\n",
    "print('LEMMATIZED')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_lancaster, y_test, verbose=1)\n",
    "print('LANCASTER')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_cleanWithStopwords)\n",
    "plot_history(history_cleanNoStopwords)\n",
    "plot_history(history_porterStemmer)\n",
    "plot_history(history_snowballStemmer)\n",
    "plot_history(history_lemmatized)\n",
    "plot_history(history_lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

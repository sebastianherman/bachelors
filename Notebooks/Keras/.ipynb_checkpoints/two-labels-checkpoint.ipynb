{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import contractions\n",
    "\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_data_5k = pd.read_csv(\"/home/sebastian/Documents/bachelor-final/Dataset/PROCESSED_RESTAURANT_REVIEWS_5k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "      <th>rating</th>\n",
       "      <th>restaurantID</th>\n",
       "      <th>reviewCleanWithStopwords</th>\n",
       "      <th>reviewCleanNoStopwords</th>\n",
       "      <th>reviewCleanPorterStemmer</th>\n",
       "      <th>reviewCleanSnowballStemmer</th>\n",
       "      <th>reviewCleanLemmatized</th>\n",
       "      <th>reviewCleanLancaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"'Check, Please.\" The bartender was unable to ...</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>VZHyAmdFDreQqL0BT-zdoA</td>\n",
       "      <td>check please the bartender was unable to recom...</td>\n",
       "      <td>check please bartender unable recommend beer t...</td>\n",
       "      <td>check pleas bartend unabl recommend beer tap t...</td>\n",
       "      <td>check pleas bartend unabl recommend beer tap t...</td>\n",
       "      <td>check please bartender unable recommend beer t...</td>\n",
       "      <td>check pleas bartend un recommend beer tap tri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"2 stars for disappointing food, one star for ...</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>tFcmrGLZNEymSnijoTPmqw</td>\n",
       "      <td>stars for disappointing food one star for grea...</td>\n",
       "      <td>stars disappointing food one star great servic...</td>\n",
       "      <td>star disappoint food one star great servic rea...</td>\n",
       "      <td>star disappoint food one star great servic rea...</td>\n",
       "      <td>star disappoint food one star great service re...</td>\n",
       "      <td>star disappoint food on star gre serv read iai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"A Divine Dialogue\" God: \"Britton. Times up. T...</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>INvIaBFnAvGxzTXFWHzGvA</td>\n",
       "      <td>divine dialogue god britton times up the world...</td>\n",
       "      <td>divine dialogue god britton times world going ...</td>\n",
       "      <td>divin dialogu god britton time world go end to...</td>\n",
       "      <td>divin dialogu god britton time world go end to...</td>\n",
       "      <td>divine dialogue god britton time world go end ...</td>\n",
       "      <td>divin dialog god britton tim world going end t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"A Place To Go When You Have Time\" It was a mi...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>FySId5SjNhkrtPA5qktdxg</td>\n",
       "      <td>place to go when you have time it was misty br...</td>\n",
       "      <td>place go time misty breezy summer night friend...</td>\n",
       "      <td>place go time misti breezi summer night friend...</td>\n",
       "      <td>place go time misti breezi summer night friend...</td>\n",
       "      <td>place go time misty breezy summer night friend...</td>\n",
       "      <td>plac go tim misty breezy sum night friend jere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"A Thaiphoon of Flavor\" My First: I never enli...</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>RgeMUiZncTs-VSHQLm0wNg</td>\n",
       "      <td>thaiphoon of flavor my first never enlisted in...</td>\n",
       "      <td>thaiphoon flavor first never enlisted air forc...</td>\n",
       "      <td>thaiphoon flavor first never enlist air forc a...</td>\n",
       "      <td>thaiphoon flavor first never enlist air forc a...</td>\n",
       "      <td>thaiphoon flavor first never enlist air force ...</td>\n",
       "      <td>thaiphoon flav first nev enl air forc allow jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      reviewContent  usefulCount  \\\n",
       "0           0  \"'Check, Please.\" The bartender was unable to ...           18   \n",
       "1           1  \"2 stars for disappointing food, one star for ...           14   \n",
       "2           2  \"A Divine Dialogue\" God: \"Britton. Times up. T...           14   \n",
       "3           3  \"A Place To Go When You Have Time\" It was a mi...           13   \n",
       "4           4  \"A Thaiphoon of Flavor\" My First: I never enli...           27   \n",
       "\n",
       "   coolCount  funnyCount  rating            restaurantID  \\\n",
       "0         11          25       1  VZHyAmdFDreQqL0BT-zdoA   \n",
       "1         10           7       3  tFcmrGLZNEymSnijoTPmqw   \n",
       "2         16          23       5  INvIaBFnAvGxzTXFWHzGvA   \n",
       "3         10          10       5  FySId5SjNhkrtPA5qktdxg   \n",
       "4         22          28       5  RgeMUiZncTs-VSHQLm0wNg   \n",
       "\n",
       "                            reviewCleanWithStopwords  \\\n",
       "0  check please the bartender was unable to recom...   \n",
       "1  stars for disappointing food one star for grea...   \n",
       "2  divine dialogue god britton times up the world...   \n",
       "3  place to go when you have time it was misty br...   \n",
       "4  thaiphoon of flavor my first never enlisted in...   \n",
       "\n",
       "                              reviewCleanNoStopwords  \\\n",
       "0  check please bartender unable recommend beer t...   \n",
       "1  stars disappointing food one star great servic...   \n",
       "2  divine dialogue god britton times world going ...   \n",
       "3  place go time misty breezy summer night friend...   \n",
       "4  thaiphoon flavor first never enlisted air forc...   \n",
       "\n",
       "                            reviewCleanPorterStemmer  \\\n",
       "0  check pleas bartend unabl recommend beer tap t...   \n",
       "1  star disappoint food one star great servic rea...   \n",
       "2  divin dialogu god britton time world go end to...   \n",
       "3  place go time misti breezi summer night friend...   \n",
       "4  thaiphoon flavor first never enlist air forc a...   \n",
       "\n",
       "                          reviewCleanSnowballStemmer  \\\n",
       "0  check pleas bartend unabl recommend beer tap t...   \n",
       "1  star disappoint food one star great servic rea...   \n",
       "2  divin dialogu god britton time world go end to...   \n",
       "3  place go time misti breezi summer night friend...   \n",
       "4  thaiphoon flavor first never enlist air forc a...   \n",
       "\n",
       "                               reviewCleanLemmatized  \\\n",
       "0  check please bartender unable recommend beer t...   \n",
       "1  star disappoint food one star great service re...   \n",
       "2  divine dialogue god britton time world go end ...   \n",
       "3  place go time misty breezy summer night friend...   \n",
       "4  thaiphoon flavor first never enlist air force ...   \n",
       "\n",
       "                                reviewCleanLancaster  \n",
       "0  check pleas bartend un recommend beer tap tri ...  \n",
       "1  star disappoint food on star gre serv read iai...  \n",
       "2  divin dialog god britton tim world going end t...  \n",
       "3  plac go tim misty breezy sum night friend jere...  \n",
       "4  thaiphoon flav first nev enl air forc allow jo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data_5k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1250\n",
       "5    1179\n",
       "1    1159\n",
       "3    1130\n",
       "4    1051\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data_5k.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data_5k.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    accuracy = history.history['acc']\n",
    "    val_accuracy = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(1,len(accuracy) + 1)\n",
    "    \n",
    "    # Plot accuracy  \n",
    "    plt.figure(1)\n",
    "    plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'g', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove 3 stars, transform 1,2 to 0 and 4,5 to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of indexes for which column rating has value 2\n",
    "indexNamesRating3 = yelp_data_5k[ yelp_data_5k['rating'] == 3 ].index\n",
    " \n",
    "# Delete these row indexes from dataFrame\n",
    "yelp_data_5k.drop(indexNamesRating3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1250\n",
       "5    1179\n",
       "1    1159\n",
       "4    1051\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data_5k.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 1 and 2 stars to rating 0 and 4 and 5 stars to rating 1\n",
    "yelp_data_5k['rating'] = yelp_data_5k['rating'].apply(lambda x: 1 if x>3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2409\n",
       "1    2230\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data_5k.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allocating each text with its specific cleaning method to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cleanWithStopwords = yelp_data_5k[\"reviewCleanWithStopwords\"]\n",
    "x_cleanNoStopwords = yelp_data_5k[\"reviewCleanNoStopwords\"]\n",
    "x_porterStemmer = yelp_data_5k[\"reviewCleanPorterStemmer\"]\n",
    "x_snowballStemmer = yelp_data_5k[\"reviewCleanSnowballStemmer\"]\n",
    "x_lemmatized = yelp_data_5k[\"reviewCleanLemmatized\"]\n",
    "x_lancaster = yelp_data_5k[\"reviewCleanLancaster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_cleanWithStopwords)\n",
    "x_cleanWithStopwords = tf.transform(x_cleanWithStopwords)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_cleanNoStopwords)\n",
    "x_cleanNoStopwords = tf.transform(x_cleanNoStopwords)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_porterStemmer)\n",
    "x_porterStemmer = tf.transform(x_porterStemmer)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_snowballStemmer)\n",
    "x_snowballStemmer = tf.transform(x_snowballStemmer)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_lemmatized)\n",
    "x_lemmatized = tf.transform(x_lemmatized)\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode', decode_error='replace', analyzer='word', min_df=5).fit(x_lancaster)\n",
    "x_lancaster = tf.transform(x_lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_cleanWithStopwords = SelectKBest(f_classif, k=min(20000, x_cleanWithStopwords.shape[1]))\n",
    "selector_cleanNoStopwords = SelectKBest(f_classif, k=min(20000, x_cleanNoStopwords.shape[1]))\n",
    "selector_porterStemmer = SelectKBest(f_classif, k=min(20000, x_porterStemmer.shape[1]))\n",
    "selector_snowballStemmer = SelectKBest(f_classif, k=min(20000, x_snowballStemmer.shape[1]))\n",
    "selector_lemmatized = SelectKBest(f_classif, k=min(20000, x_lemmatized.shape[1]))\n",
    "selector_lancaster = SelectKBest(f_classif, k=min(20000, x_lancaster.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = yelp_data_5k.rating.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=20000, score_func=<function f_classif at 0x7f2bbf3c5b70>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_cleanWithStopwords.fit(x_cleanWithStopwords, y)\n",
    "selector_cleanNoStopwords.fit(x_cleanNoStopwords, y)\n",
    "selector_porterStemmer.fit(x_porterStemmer, y)\n",
    "selector_snowballStemmer.fit(x_snowballStemmer, y)\n",
    "selector_lemmatized.fit(x_lemmatized, y)\n",
    "selector_lancaster.fit(x_lancaster, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cleanWithStopwords = selector_cleanWithStopwords.transform(x_cleanWithStopwords).astype('float32')\n",
    "x_cleanNoStopwords = selector_cleanNoStopwords.transform(x_cleanNoStopwords).astype('float32')\n",
    "x_porterStemmer = selector_porterStemmer.transform(x_porterStemmer).astype('float32')\n",
    "x_snowballStemmer = selector_snowballStemmer.transform(x_snowballStemmer).astype('float32')\n",
    "x_lemmatized = selector_lemmatized.transform(x_lemmatized).astype('float32')\n",
    "x_lancaster = selector_lancaster.transform(x_lancaster).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleanWithStopwords = x_cleanWithStopwords.toarray()\n",
    "X_cleanNoStopwords = x_cleanNoStopwords.toarray()\n",
    "X_porterStemmer = x_porterStemmer.toarray()\n",
    "X_snowballStemmer = x_snowballStemmer.toarray()\n",
    "X_lemmatized = x_lemmatized.toarray()\n",
    "X_lancaster = x_lancaster.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (np.array(yelp_data_5k['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleanWithStopwords, X_test_cleanWithStopwords, y_train, y_test = train_test_split(X_cleanWithStopwords, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_cleanNoStopwords, X_test_cleanNoStopwords, y_train, y_test = train_test_split(X_cleanNoStopwords, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_porterStemmer, X_test_porterStemmer, y_train, y_test = train_test_split(X_porterStemmer, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_snowballStemmer, X_test_snowballStemmer, y_train, y_test = train_test_split(X_snowballStemmer, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_lemmatized, X_test_lemmatized, y_train, y_test = train_test_split(X_lemmatized, y, test_size=0.2, random_state=50)\n",
    "\n",
    "X_train_lancaster, X_test_lancaster, y_train, y_test = train_test_split(X_lancaster, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train_cleanNoStopwords.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 18:39:57.248036 139827133867840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0703 18:39:57.257607 139827133867840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0703 18:39:57.259047 139827133867840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0703 18:39:57.263933 139827133867840 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0703 18:39:57.274459 139827133867840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_1 (Dropout)          (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1280064   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(rate=0.2, input_shape = input_shape))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 18:39:57.317142 139827133867840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0703 18:39:57.320824 139827133867840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0703 18:39:57.324256 139827133867840 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(X_train_cleanNoStopwords, y_train, epochs=100, validation_data=(X_test_cleanNoStopwords, y_test), verbose=1, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, compare how the model performs on the test dataset:\n",
    "#test_loss, test_acc = model.evaluate(X_test_cleanNoStopwords, y_test, verbose=1)\n",
    "#print('Test loss:', test_loss)\n",
    "#print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3711 samples, validate on 928 samples\n",
      "Epoch 1/100\n",
      "3711/3711 [==============================] - 1s 276us/step - loss: 0.5924 - acc: 0.8583 - val_loss: 0.4735 - val_acc: 0.9203\n",
      "Epoch 2/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.3549 - acc: 0.9407 - val_loss: 0.3021 - val_acc: 0.9407\n",
      "Epoch 3/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.2173 - acc: 0.9607 - val_loss: 0.2152 - val_acc: 0.9558\n",
      "Epoch 4/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.1390 - acc: 0.9793 - val_loss: 0.1659 - val_acc: 0.9623\n",
      "Epoch 5/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0957 - acc: 0.9919 - val_loss: 0.1374 - val_acc: 0.9688\n",
      "Epoch 6/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0688 - acc: 0.9933 - val_loss: 0.1197 - val_acc: 0.9731\n",
      "Epoch 7/100\n",
      "3711/3711 [==============================] - 0s 77us/step - loss: 0.0503 - acc: 0.9965 - val_loss: 0.1074 - val_acc: 0.9731\n",
      "Epoch 8/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0378 - acc: 0.9984 - val_loss: 0.0994 - val_acc: 0.9731\n",
      "Epoch 9/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0300 - acc: 0.9984 - val_loss: 0.0933 - val_acc: 0.9720\n",
      "Epoch 10/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0235 - acc: 0.9997 - val_loss: 0.0890 - val_acc: 0.9731\n",
      "Epoch 11/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0198 - acc: 0.9997 - val_loss: 0.0864 - val_acc: 0.9709\n",
      "Epoch 12/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0162 - acc: 0.9997 - val_loss: 0.0830 - val_acc: 0.9709\n",
      "Epoch 13/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.0811 - val_acc: 0.9709\n",
      "Epoch 14/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 0.9731\n",
      "Epoch 15/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 0.9731\n",
      "Epoch 16/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0773 - val_acc: 0.9731\n",
      "Epoch 17/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0762 - val_acc: 0.9741\n",
      "Epoch 18/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 0.9741\n",
      "Epoch 19/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0746 - val_acc: 0.9731\n",
      "Epoch 20/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 0.0739 - val_acc: 0.9731\n",
      "Epoch 21/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9731\n",
      "Epoch 22/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0047 - acc: 0.9997 - val_loss: 0.0733 - val_acc: 0.9731\n",
      "Epoch 23/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0734 - val_acc: 0.9741\n",
      "Epoch 24/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0732 - val_acc: 0.9731\n",
      "Epoch 25/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0727 - val_acc: 0.9741\n",
      "Epoch 26/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0730 - val_acc: 0.9741\n",
      "Epoch 27/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0723 - val_acc: 0.9741\n",
      "Epoch 28/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0727 - val_acc: 0.9741\n",
      "Epoch 29/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0726 - val_acc: 0.9731\n",
      "Train on 3711 samples, validate on 928 samples\n",
      "Epoch 1/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.6042 - acc: 0.7440 - val_loss: 0.3245 - val_acc: 0.8599\n",
      "Epoch 2/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.1822 - acc: 0.9340 - val_loss: 0.2534 - val_acc: 0.8966\n",
      "Epoch 3/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.1008 - acc: 0.9712 - val_loss: 0.2252 - val_acc: 0.9116\n",
      "Epoch 4/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0651 - acc: 0.9849 - val_loss: 0.2128 - val_acc: 0.9181\n",
      "Epoch 5/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0457 - acc: 0.9903 - val_loss: 0.2081 - val_acc: 0.9159\n",
      "Epoch 6/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0330 - acc: 0.9943 - val_loss: 0.2043 - val_acc: 0.9203\n",
      "Epoch 7/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0247 - acc: 0.9962 - val_loss: 0.2038 - val_acc: 0.9213\n",
      "Epoch 8/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0203 - acc: 0.9968 - val_loss: 0.2025 - val_acc: 0.9235\n",
      "Epoch 9/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0186 - acc: 0.9962 - val_loss: 0.2007 - val_acc: 0.9192\n",
      "Epoch 10/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0153 - acc: 0.9984 - val_loss: 0.2000 - val_acc: 0.9246\n",
      "Epoch 11/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0125 - acc: 0.9984 - val_loss: 0.2013 - val_acc: 0.9235\n",
      "Epoch 12/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0111 - acc: 0.9992 - val_loss: 0.2016 - val_acc: 0.9235\n",
      "Train on 3711 samples, validate on 928 samples\n",
      "Epoch 1/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.7755 - acc: 0.7141 - val_loss: 0.3670 - val_acc: 0.8394\n",
      "Epoch 2/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.2143 - acc: 0.9173 - val_loss: 0.3050 - val_acc: 0.8675\n",
      "Epoch 3/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.1395 - acc: 0.9518 - val_loss: 0.2767 - val_acc: 0.8815\n",
      "Epoch 4/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0977 - acc: 0.9685 - val_loss: 0.2597 - val_acc: 0.8879\n",
      "Epoch 5/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0724 - acc: 0.9811 - val_loss: 0.2465 - val_acc: 0.8922\n",
      "Epoch 6/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0545 - acc: 0.9863 - val_loss: 0.2379 - val_acc: 0.8976\n",
      "Epoch 7/100\n",
      "3711/3711 [==============================] - 0s 77us/step - loss: 0.0466 - acc: 0.9903 - val_loss: 0.2320 - val_acc: 0.9030\n",
      "Epoch 8/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0371 - acc: 0.9922 - val_loss: 0.2288 - val_acc: 0.9073\n",
      "Epoch 9/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0286 - acc: 0.9957 - val_loss: 0.2257 - val_acc: 0.9106\n",
      "Epoch 10/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0260 - acc: 0.9954 - val_loss: 0.2239 - val_acc: 0.9138\n",
      "Epoch 11/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0221 - acc: 0.9960 - val_loss: 0.2221 - val_acc: 0.9149\n",
      "Epoch 12/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0172 - acc: 0.9989 - val_loss: 0.2213 - val_acc: 0.9127\n",
      "Epoch 13/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0177 - acc: 0.9970 - val_loss: 0.2206 - val_acc: 0.9149\n",
      "Epoch 14/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0168 - acc: 0.9987 - val_loss: 0.2205 - val_acc: 0.9138\n",
      "Epoch 15/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0146 - acc: 0.9981 - val_loss: 0.2181 - val_acc: 0.9170\n",
      "Epoch 16/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0125 - acc: 0.9987 - val_loss: 0.2182 - val_acc: 0.9170\n",
      "Epoch 17/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0131 - acc: 0.9978 - val_loss: 0.2172 - val_acc: 0.9192\n",
      "Epoch 18/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0117 - acc: 0.9987 - val_loss: 0.2157 - val_acc: 0.9203\n",
      "Epoch 19/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0098 - acc: 0.9995 - val_loss: 0.2153 - val_acc: 0.9203\n",
      "Epoch 20/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0105 - acc: 0.9984 - val_loss: 0.2139 - val_acc: 0.9192\n",
      "Epoch 21/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.2138 - val_acc: 0.9213\n",
      "Epoch 22/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0072 - acc: 0.9997 - val_loss: 0.2170 - val_acc: 0.9159\n",
      "Epoch 23/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.2152 - val_acc: 0.9213\n",
      "Train on 3711 samples, validate on 928 samples\n",
      "Epoch 1/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.6834 - acc: 0.7602 - val_loss: 0.3229 - val_acc: 0.8556\n",
      "Epoch 2/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.2014 - acc: 0.9170 - val_loss: 0.2688 - val_acc: 0.8944\n",
      "Epoch 3/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.1316 - acc: 0.9534 - val_loss: 0.2444 - val_acc: 0.9106\n",
      "Epoch 4/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0915 - acc: 0.9690 - val_loss: 0.2321 - val_acc: 0.9073\n",
      "Epoch 5/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0706 - acc: 0.9809 - val_loss: 0.2244 - val_acc: 0.9084\n",
      "Epoch 6/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0545 - acc: 0.9860 - val_loss: 0.2180 - val_acc: 0.9106\n",
      "Epoch 7/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0461 - acc: 0.9876 - val_loss: 0.2157 - val_acc: 0.9116\n",
      "Epoch 8/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0391 - acc: 0.9922 - val_loss: 0.2119 - val_acc: 0.9138\n",
      "Epoch 9/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0317 - acc: 0.9930 - val_loss: 0.2098 - val_acc: 0.9159\n",
      "Epoch 10/100\n",
      "3711/3711 [==============================] - 0s 71us/step - loss: 0.0268 - acc: 0.9946 - val_loss: 0.2103 - val_acc: 0.9138\n",
      "Epoch 11/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0233 - acc: 0.9954 - val_loss: 0.2080 - val_acc: 0.9181\n",
      "Epoch 12/100\n",
      "3711/3711 [==============================] - 0s 71us/step - loss: 0.0223 - acc: 0.9949 - val_loss: 0.2045 - val_acc: 0.9181\n",
      "Epoch 13/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0178 - acc: 0.9976 - val_loss: 0.2035 - val_acc: 0.9170\n",
      "Epoch 14/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0151 - acc: 0.9973 - val_loss: 0.2048 - val_acc: 0.9159\n",
      "Epoch 15/100\n",
      "3711/3711 [==============================] - 0s 71us/step - loss: 0.0154 - acc: 0.9960 - val_loss: 0.2034 - val_acc: 0.9192\n",
      "Epoch 16/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0128 - acc: 0.9987 - val_loss: 0.2045 - val_acc: 0.9181\n",
      "Epoch 17/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0136 - acc: 0.9968 - val_loss: 0.2047 - val_acc: 0.9203\n",
      "Train on 3711 samples, validate on 928 samples\n",
      "Epoch 1/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.8351 - acc: 0.7162 - val_loss: 0.4024 - val_acc: 0.8276\n",
      "Epoch 2/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.2789 - acc: 0.8954 - val_loss: 0.3314 - val_acc: 0.8599\n",
      "Epoch 3/100\n",
      "3711/3711 [==============================] - 0s 71us/step - loss: 0.1867 - acc: 0.9297 - val_loss: 0.3005 - val_acc: 0.8739\n",
      "Epoch 4/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.1329 - acc: 0.9526 - val_loss: 0.2799 - val_acc: 0.8836\n",
      "Epoch 5/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.1054 - acc: 0.9642 - val_loss: 0.2689 - val_acc: 0.8901\n",
      "Epoch 6/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0807 - acc: 0.9763 - val_loss: 0.2593 - val_acc: 0.8933\n",
      "Epoch 7/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0646 - acc: 0.9830 - val_loss: 0.2506 - val_acc: 0.8966\n",
      "Epoch 8/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0508 - acc: 0.9898 - val_loss: 0.2498 - val_acc: 0.8966\n",
      "Epoch 9/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0461 - acc: 0.9895 - val_loss: 0.2457 - val_acc: 0.9052\n",
      "Epoch 10/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0349 - acc: 0.9935 - val_loss: 0.2452 - val_acc: 0.9062\n",
      "Epoch 11/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0352 - acc: 0.9933 - val_loss: 0.2420 - val_acc: 0.9052\n",
      "Epoch 12/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0294 - acc: 0.9946 - val_loss: 0.2396 - val_acc: 0.9106\n",
      "Epoch 13/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0254 - acc: 0.9949 - val_loss: 0.2386 - val_acc: 0.9138\n",
      "Epoch 14/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0235 - acc: 0.9946 - val_loss: 0.2375 - val_acc: 0.9127\n",
      "Epoch 15/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0220 - acc: 0.9957 - val_loss: 0.2329 - val_acc: 0.9149\n",
      "Epoch 16/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0200 - acc: 0.9965 - val_loss: 0.2330 - val_acc: 0.9149\n",
      "Epoch 17/100\n",
      "3711/3711 [==============================] - 0s 71us/step - loss: 0.0159 - acc: 0.9984 - val_loss: 0.2323 - val_acc: 0.9213\n",
      "Epoch 18/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0163 - acc: 0.9976 - val_loss: 0.2340 - val_acc: 0.9170\n",
      "Epoch 19/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0158 - acc: 0.9976 - val_loss: 0.2328 - val_acc: 0.9213\n",
      "Train on 3711 samples, validate on 928 samples\n",
      "Epoch 1/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.9001 - acc: 0.6845 - val_loss: 0.4344 - val_acc: 0.8233\n",
      "Epoch 2/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.3161 - acc: 0.8731 - val_loss: 0.3547 - val_acc: 0.8599\n",
      "Epoch 3/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.2144 - acc: 0.9175 - val_loss: 0.3161 - val_acc: 0.8782\n",
      "Epoch 4/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.1591 - acc: 0.9431 - val_loss: 0.2927 - val_acc: 0.8944\n",
      "Epoch 5/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.1274 - acc: 0.9553 - val_loss: 0.2772 - val_acc: 0.8998\n",
      "Epoch 6/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.1071 - acc: 0.9650 - val_loss: 0.2650 - val_acc: 0.8998\n",
      "Epoch 7/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0802 - acc: 0.9779 - val_loss: 0.2582 - val_acc: 0.9019\n",
      "Epoch 8/100\n",
      "3711/3711 [==============================] - 0s 76us/step - loss: 0.0708 - acc: 0.9801 - val_loss: 0.2514 - val_acc: 0.9062\n",
      "Epoch 9/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0607 - acc: 0.9833 - val_loss: 0.2455 - val_acc: 0.9062\n",
      "Epoch 10/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0486 - acc: 0.9890 - val_loss: 0.2427 - val_acc: 0.9084\n",
      "Epoch 11/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0430 - acc: 0.9898 - val_loss: 0.2387 - val_acc: 0.9106\n",
      "Epoch 12/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0392 - acc: 0.9911 - val_loss: 0.2366 - val_acc: 0.9159\n",
      "Epoch 13/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0361 - acc: 0.9927 - val_loss: 0.2351 - val_acc: 0.9138\n",
      "Epoch 14/100\n",
      "3711/3711 [==============================] - 0s 74us/step - loss: 0.0329 - acc: 0.9927 - val_loss: 0.2351 - val_acc: 0.9116\n",
      "Epoch 15/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0283 - acc: 0.9946 - val_loss: 0.2328 - val_acc: 0.9106\n",
      "Epoch 16/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0267 - acc: 0.9951 - val_loss: 0.2307 - val_acc: 0.9149\n",
      "Epoch 17/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0236 - acc: 0.9951 - val_loss: 0.2301 - val_acc: 0.9159\n",
      "Epoch 18/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0216 - acc: 0.9965 - val_loss: 0.2284 - val_acc: 0.9159\n",
      "Epoch 19/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0187 - acc: 0.9968 - val_loss: 0.2284 - val_acc: 0.9170\n",
      "Epoch 20/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0205 - acc: 0.9968 - val_loss: 0.2276 - val_acc: 0.9213\n",
      "Epoch 21/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0165 - acc: 0.9978 - val_loss: 0.2269 - val_acc: 0.9159\n",
      "Epoch 22/100\n",
      "3711/3711 [==============================] - 0s 72us/step - loss: 0.0172 - acc: 0.9976 - val_loss: 0.2254 - val_acc: 0.9170\n",
      "Epoch 23/100\n",
      "3711/3711 [==============================] - 0s 71us/step - loss: 0.0131 - acc: 0.9987 - val_loss: 0.2254 - val_acc: 0.9213\n",
      "Epoch 24/100\n",
      "3711/3711 [==============================] - 0s 75us/step - loss: 0.0136 - acc: 0.9981 - val_loss: 0.2248 - val_acc: 0.9213\n",
      "Epoch 25/100\n",
      "3711/3711 [==============================] - 0s 73us/step - loss: 0.0151 - acc: 0.9965 - val_loss: 0.2251 - val_acc: 0.9181\n",
      "Epoch 26/100\n",
      "3711/3711 [==============================] - 0s 71us/step - loss: 0.0116 - acc: 0.9984 - val_loss: 0.2260 - val_acc: 0.9235\n"
     ]
    }
   ],
   "source": [
    "history_cleanWithStopwords = model.fit(X_train_cleanWithStopwords, y_train, epochs=100, validation_data=(X_test_cleanWithStopwords, y_test), verbose=1, batch_size=64, callbacks=callbacks)\n",
    "\n",
    "history_cleanNoStopwords = model.fit(X_train_cleanNoStopwords, y_train, epochs=100, validation_data=(X_test_cleanNoStopwords, y_test), verbose=1, batch_size=64, callbacks=callbacks)\n",
    "\n",
    "history_porterStemmer = model.fit(X_train_porterStemmer, y_train, epochs=100, validation_data=(X_test_porterStemmer, y_test), verbose=1, batch_size=64, callbacks=callbacks)\n",
    "\n",
    "history_snowballStemmer = model.fit(X_train_snowballStemmer, y_train, epochs=100, validation_data=(X_test_snowballStemmer, y_test), verbose=1, batch_size=64, callbacks=callbacks)\n",
    "\n",
    "history_lemmatized = model.fit(X_train_lemmatized, y_train, epochs=100, validation_data=(X_test_lemmatized, y_test), verbose=1, batch_size=64, callbacks=callbacks)\n",
    "\n",
    "history_lancaster = model.fit(X_train_lancaster, y_train, epochs=100, validation_data=(X_test_lancaster, y_test), verbose=1, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/928 [==============================] - 0s 49us/step\n",
      "WITH STOPWORDS\n",
      "Test loss: 0.42479664241445475\n",
      "Test accuracy: 0.8243534482758621\n",
      "928/928 [==============================] - 0s 47us/step\n",
      "NO STOPWORDS\n",
      "Test loss: 0.5380365941031225\n",
      "Test accuracy: 0.8081896551724138\n",
      "928/928 [==============================] - 0s 47us/step\n",
      "PORTERSTEMMER\n",
      "Test loss: 0.43863908432680987\n",
      "Test accuracy: 0.8469827586206896\n",
      "928/928 [==============================] - 0s 44us/step\n",
      "SNOWBALLSTEMMER\n",
      "Test loss: 0.34894628206203726\n",
      "Test accuracy: 0.8900862068965517\n",
      "928/928 [==============================] - 0s 48us/step\n",
      "LEMMATIZED\n",
      "Test loss: 0.2874983174019846\n",
      "Test accuracy: 0.9008620689655172\n",
      "928/928 [==============================] - 0s 48us/step\n",
      "LANCASTER\n",
      "Test loss: 0.22595291443426033\n",
      "Test accuracy: 0.9234913793103449\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_cleanWithStopwords, y_test, verbose=1)\n",
    "print('WITH STOPWORDS')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_cleanNoStopwords, y_test, verbose=1)\n",
    "print('NO STOPWORDS')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_porterStemmer, y_test, verbose=1)\n",
    "print('PORTERSTEMMER')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_snowballStemmer, y_test, verbose=1)\n",
    "print('SNOWBALLSTEMMER')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_lemmatized, y_test, verbose=1)\n",
    "print('LEMMATIZED')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_lancaster, y_test, verbose=1)\n",
    "print('LANCASTER')\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_cleanWithStopwords)\n",
    "plot_history(history_cleanNoStopwords)\n",
    "plot_history(history_porterStemmer)\n",
    "plot_history(history_snowballStemmer)\n",
    "plot_history(history_lemmatized)\n",
    "plot_history(history_lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
